# -*- coding: utf-8 -*-
"""finl ss

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lQ61Ci1lVIJkqNK859w8qpfy9D_gYIO_
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from sklearn.feature_extraction.text import CountVectorizer
from nltk.sentiment import SentimentIntensityAnalyzer
import seaborn as sns
import nltk

# Ensure necessary nltk resources are downloaded
nltk.download("vader_lexicon")

# Title and Description
st.title("Amazon Product Review Sentiment Analysis")
st.markdown(
    """
    This app performs sentiment analysis on Amazon product reviews, 
    showcasing insights and visualizations based on textual data.
    """
)

# File Uploader
uploaded_file = st.file_uploader("Upload a CSV file containing product reviews", type=["csv"])

if uploaded_file:
    # Load dataset
    try:
        df = pd.read_csv(uploaded_file)
        st.write("### Dataset Preview")
        st.write(df.head())

        # Dropdown to select review column
        text_column = st.selectbox("Select the review text column:", df.columns)

        # Sentiment Analysis
        st.subheader("Sentiment Analysis")
        sia = SentimentIntensityAnalyzer()

        def analyze_sentiment(text):
            scores = sia.polarity_scores(text)
            if scores['compound'] > 0.05:
                return "Positive"
            elif scores['compound'] < -0.05:
                return "Negative"
            else:
                return "Neutral"

        df["Sentiment"] = df[text_column].apply(analyze_sentiment)
        sentiment_counts = df["Sentiment"].value_counts()
        st.write(sentiment_counts)

        # Sentiment Distribution
        st.subheader("Sentiment Distribution")
        fig, ax = plt.subplots()
        sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, ax=ax, palette="viridis")
        ax.set_title("Sentiment Distribution")
        ax.set_xlabel("Sentiment")
        ax.set_ylabel("Counts")
        st.pyplot(fig)

        # Word Cloud
        st.subheader("Word Cloud for Reviews")
        all_text = " ".join(df[text_column].dropna())
        wordcloud = WordCloud(width=800, height=400, background_color="white").generate(all_text)
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.imshow(wordcloud, interpolation="bilinear")
        ax.axis("off")
        st.pyplot(fig)

        # Frequent Words
        st.subheader("Top Frequent Words")
        vectorizer = CountVectorizer(stop_words="english", max_features=10)
        word_counts = vectorizer.fit_transform(df[text_column].dropna())
        word_freq = dict(zip(vectorizer.get_feature_names_out(), word_counts.toarray().sum(axis=0)))
        sorted_word_freq = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        frequent_words = pd.DataFrame(sorted_word_freq, columns=["Word", "Frequency"])
        st.write(frequent_words)

    except Exception as e:
        st.error(f"Error processing file: {e}")

else:
    st.info("Awaiting file upload. Please upload a CSV file to proceed.")

